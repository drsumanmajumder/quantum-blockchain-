{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd8fd10",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from qiskit import Aer, QuantumCircuit\n",
    "from qiskit.circuit.library import TwoLocal\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit_machine_learning.algorithms import VQC\n",
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
    "from qiskit_machine_learning.neural_networks import CircuitQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "\n",
    "# Define seed for reproducibility\n",
    "algorithm_globals.random_seed = 42\n",
    "\n",
    "# Load and prepare the data\n",
    "data_path = \"path/to/your/sample.csv\"  # Update this path to your dataset location\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Assuming 'y' is the label column\n",
    "df_labels = df['y']\n",
    "df_features = df.drop(['y'], axis=1)\n",
    "\n",
    "# Split dataset into train and test\n",
    "sample_train, sample_test, label_train, label_test = train_test_split(df_features, df_labels, test_size=0.2, random_state=22)\n",
    "\n",
    "# Apply PCA to reduce dimensions\n",
    "n_dim = 2\n",
    "pca = PCA(n_components=n_dim).fit(sample_train)\n",
    "sample_train = pca.transform(sample_train)\n",
    "sample_test = pca.transform(sample_test)\n",
    "\n",
    "# Normalize the data\n",
    "std_scale = StandardScaler().fit(sample_train)\n",
    "sample_train = std_scale.transform(sample_train)\n",
    "sample_test = std_scale.transform(sample_test)\n",
    "\n",
    "# Scale for better fit within the feature map\n",
    "samples = np.append(sample_train, sample_test, axis=0)\n",
    "minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\n",
    "sample_train = minmax_scale.transform(sample_train)\n",
    "sample_test = minmax_scale.transform(sample_test)\n",
    "\n",
    "# Define the feature map\n",
    "feature_map = RawFeatureVector(feature_dimension=n_dim)\n",
    "\n",
    "# Define the variational circuit\n",
    "var_circuit = TwoLocal(n_dim, 'ry', 'cz', reps=3, entanglement='full')\n",
    "\n",
    "# Define the quantum instance\n",
    "backend = QuantumInstance(Aer.get_backend('aer_simulator_statevector'))\n",
    "\n",
    "# Define the QNN\n",
    "qnn = CircuitQNN(circuit=var_circuit, input_params=feature_map.parameters, weight_params=var_circuit.parameters, quantum_instance=backend)\n",
    "\n",
    "# Convert QNN to PyTorch model\n",
    "torch_qnn = TorchConnector(qnn)\n",
    "model = torch.nn.Sequential(\n",
    "    torch_qnn,\n",
    "    torch.nn.Linear(qnn.output_shape[0], 2)\n",
    ")\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(sample_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(label_train.values, dtype=torch.long)\n",
    "X_test = torch.tensor(sample_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(label_test.values, dtype=torch.long)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = loss_fn(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_output = model(X_test)\n",
    "    predictions = torch.argmax(test_output, dim=1)\n",
    "    confidence_scores = torch.nn.functional.softmax(test_output, dim=1).max(dim=1)[0].numpy()\n",
    "    predicted_labels = predictions.numpy()\n",
    "\n",
    "# Generate output table\n",
    "output_table = pd.DataFrame({\n",
    "    \"Sample\": range(1, len(predicted_labels) + 1),\n",
    "    \"Predicted Label\": [\"Positive\" if label == 1 else \"Negative\" for label in predicted_labels],\n",
    "    \"Confidence Score\": confidence_scores\n",
    "})\n",
    "\n",
    "print(output_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
